Cancellation.java
import java.io.File;
import java.io.FileWriter;
import java.io.IOException;
import java.util.TreeSet;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.io.DoubleWritable;
import org.apache.hadoop.io.LongWritable;
public class Cancellation {
public static TreeSet<OutputPair> sortedOutput = new
TreeSet<>();
public static class Map extends Mapper<LongWritable, Text,
Text, LongWritable> {
public void map(LongWritable key, Text value, Context
context) throws IOException, InterruptedException {
String[] elements = value.toString().split(",");
String canc = elements[22].trim();
if ((!canc.equalsIgnoreCase("")) && 
!canc.equalsIgnoreCase("CancellationCode") &&
!canc.equalsIgnoreCase("NA")) {
// int taxiIn = Integer.parseInt(In);
context.write(new Text(canc), new
LongWritable(1));
}
}
}
public static class Reduce extends Reducer<Text, LongWritable,
Text, LongWritable> {
private DoubleWritable sumCount = new
DoubleWritable();
private DoubleWritable relativeCount = new
DoubleWritable();
private Text currentElement = new Text("B-L-A-N-K / E-MP-T-Y");
private LongWritable result = new LongWritable();
public void reduce(Text key, Iterable<LongWritable>
values, Context context)
throws IOException, InterruptedException {
long result1;
long sum = 0;
for (LongWritable val : values) {
sum += val.get();
}
result1 = sum;
result.set(sum);
sortedOutput.add(new OutputPair(result1, 
key.toString()));
context.write(key, result);
if (sortedOutput.size() > 1) {
sortedOutput.pollLast();
}
}
}
public static void main(String[] args) throws Exception {
Job job = Job.getInstance(new Configuration());
job.setJarByClass(Cancellation.class);
job.setMapperClass(Map.class);
job.setReducerClass(Reduce.class);
FileInputFormat.addInputPath(job, new Path(args[0]));
FileOutputFormat.setOutputPath(job, new Path(args[1]));
job.setMapOutputKeyClass(Text.class);
job.setMapOutputValueClass(LongWritable.class);
job.setOutputKeyClass(Text.class);
job.setOutputValueClass(LongWritable.class);
job.waitForCompletion(true);
File file1 = new File(args[1] + "/MostcommonReason.txt");
file1.createNewFile();
FileWriter fw1 = new FileWriter(file1);
for (OutputPair now : sortedOutput) {
String code = now.key ;
System.out.println(code);
if(code.equals("A")){
fw1.write("Cancellation Reason -> Carrier No
of happenings -> " + now.result2 + "\n");
}
else if(code.equals("B")){
fw1.write("Cancellation Reason -> weather 
No of happenings -> " + now.result2 + "\n");
}
else if(code.equals("C")){
fw1.write("Cancellation Reason -> NAS No of
happenings -> " + now.result2 + "\n");
}
else if(code.equals("D")){
fw1.write("Cancellation Reason -> security
No of happenings -> " + now.result2 + "\n");
}
else if(code.equals(null)){
fw1.write("Cancellation Reason -> NA");
}
}
fw1.close();
/*
* fw1.close(); File file2 = new File(args[1] +
"/bottom3.txt");
* file2.createNewFile(); FileWriter fw2 = new
FileWriter(file2); for
* (OutputPair now : sortedOutput2) { fw2.write("Airport
name -> " +
* now.key + " Lowest average time-> " + now.average +
"\n"); }
* fw2.close();
*/
}
public static class OutputPair implements
Comparable<OutputPair> {
long result2;
String key;
OutputPair(long result2, String key) {
this.result2 = result2;
this.key = key;
}
@Override
public int compareTo(OutputPair outputPair) {
if (this.result2 <= outputPair.result2) {
return 1;
} else {
return -1;
}
}
}
}
FlightDelay.java
import java.io.File;
import java.io.FileWriter;
import java.io.IOException;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import java.util.TreeSet;
import org.apache.hadoop.io.DoubleWritable;
import org.apache.hadoop.io.LongWritable;
public class FlightDelay {
public static TreeSet<OutputPair> sortedOutput = new
TreeSet<>();
public static TreeSet<OutputPair> sortedOutput2 = new
TreeSet<>();
// public static TreeSet<OutputPair> HighestProbablitytop3 =
new
// TreeSet<>();
// public static TreeSet<OutputPair> LowestProbablitytop3 =
new TreeSet<>();
public static class Map extends
Mapper<LongWritable, Text, Text, LongWritable> {
public void map(LongWritable key, Text value, Context
context)
throws IOException, InterruptedException {
String[] elements = value.toString().split(",");
String airlines = elements[8].trim();
String arrivalDelay = elements[14].trim();
String departureDelay = elements[15].trim();
if (!arrivalDelay.equalsIgnoreCase("ArrDelay")
&& !arrivalDelay.equalsIgnoreCase("NA")
&&
!departureDelay.equalsIgnoreCase("DepDelay")
&&
!departureDelay.equalsIgnoreCase("NA")) {
if (Integer.parseInt(arrivalDelay) <= 10
&&
Integer.parseInt(departureDelay) <= 10) {
//
System.out.println(Integer.parseInt(ad));
context.write(new Text(airlines + " " + 
"ontime"),
new LongWritable(1));
}
context.write(new Text(airlines + " " + "all"),
new LongWritable(1));
}
}
}
public static class Reduce extends Reducer<Text, LongWritable,
Text, Text> {
private DoubleWritable sumCount = new
DoubleWritable();
private DoubleWritable relativeCount = new
DoubleWritable();
private Text currentElement = new Text("B-L-A-N-K / E-MP-T-Y");
public void reduce(Text key, Iterable<LongWritable>
values,
Context context) throws IOException,
InterruptedException {
String[] keyComp = key.toString().split(" ");
if (keyComp[1].equals("all")) {
if
(keyComp[0].equals(currentElement.toString())) {
sumCount.set(sumCount.get() +
fetchSumCount(values));
} else {
currentElement.set(keyComp[0]);
sumCount.set(0);
sumCount.set(fetchSumCount(values));
}
} else {
// on schedule count is count
// total airlines count is sumCount
double count = fetchSumCount(values);
relativeCount.set((double) count /
sumCount.get());
Double relativeCountD = relativeCount.get();
sortedOutput.add(new
OutputPair(relativeCountD,count, key.toString(),
currentElement.toString()));
sortedOutput2.add(new
OutputPair(relativeCountD,count, key.toString(),
currentElement.toString()));
//System.out.println(sortedOutput.size()+ " soterd output size check
");
if (sortedOutput.size() > 3) {
sortedOutput.pollLast();
}
if (sortedOutput2.size() > 3) {
sortedOutput2.pollFirst();
}
/*
* HighestProbablitytop3.add(new
*
OutputPair(relativeCountD,currentElement.toString()));
* LowestProbablitytop3.add(new
*
OutputPair(relativeCountD,currentElement.toString()));
*
* if(HighestProbablitytop3.size()>3){
* HighestProbablitytop3.pollLast(); }
* if(LowestProbablitytop3.size()>3){
* LowestProbablitytop3.pollFirst(); }
*/
context.write(key,
new
Text(Double.toString(relativeCountD)));
//System.out.println("printing in reducer");
//System.out.println(keyComp[0] + " space"
// + relativeCountD);
}
}
private double fetchSumCount(Iterable<LongWritable>
values) {
double count1 = 0;
for (LongWritable value : values) {
count1 += value.get();
}
return count1;
}
}
public static void main(String[] args) throws Exception {
Job job = Job.getInstance(new Configuration());
job.setJarByClass(FlightDelay.class);
job.setMapperClass(Map.class);
job.setReducerClass(Reduce.class);
FileInputFormat.addInputPath(job, new Path(args[0]));
FileOutputFormat.setOutputPath(job, new Path(args[1]));
job.setMapOutputKeyClass(Text.class);
job.setMapOutputValueClass(LongWritable.class);
job.setOutputKeyClass(Text.class);
job.setOutputValueClass(LongWritable.class);
job.waitForCompletion(true);
File file1 = new File(args[1] + "/top3.txt");
file1.createNewFile();
FileWriter fw1 = new FileWriter(file1);
for (OutputPair now : sortedOutput) {
fw1.write( "Airlines name -> " + now.value + "
Highest Probability for being on schedule-> " +
now.relativeFrequency + "\n");
}
fw1.close();
File file2 = new File(args[1] + "/bottom3.txt");
file2.createNewFile();
FileWriter fw2 = new FileWriter(file2);
for (OutputPair now : sortedOutput2) {
fw2.write( "Airlines name -> " + now.value + "
Lowest Probability for being on schedule-> " +
now.relativeFrequency + "\n");
}
fw2.close();

}
public static class OutputPair implements
Comparable<OutputPair> {
double relativeFrequency;
double count;
String key;
String value;
OutputPair(double relativeFrequency, double count,
String key, String value) {
this.relativeFrequency = relativeFrequency;
this.count = count;
this.key = key;
this.value = value;
}
@Override
public int compareTo(OutputPair outputPair) {
if(this.relativeFrequency<=outputPair.relativeFrequency){
return 1;
} else {
return -1;
}
}
}
}
Taxi.java
import java.io.File;
import java.io.FileWriter;
import java.io.IOException;
import java.util.TreeSet;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.io.DoubleWritable;
import org.apache.hadoop.io.LongWritable;
public class TaxiAverage {
public static TreeSet<OutputPair> sortedOutput = new
TreeSet<>();
public static TreeSet<OutputPair> sortedOutput2 = new
TreeSet<>();
// public static TreeSet<OutputPair> HighestProbablitytop3 =
new
// TreeSet<>();
// public static TreeSet<OutputPair> LowestProbablitytop3 =
new TreeSet<>();
public static class Map extends
Mapper<LongWritable, Text, Text, LongWritable> {
public void map(LongWritable key, Text value, Context
context)
throws IOException, InterruptedException {
String[] elements = value.toString().split(",");
String airportorigin = elements[16].trim();
String airportdep = elements[17].trim();
String In = elements[19].trim();
String Out = elements[20].trim();
if(isInteger(In)){
int taxiIn = Integer.parseInt(In);
context.write(new Text(airportorigin), new
LongWritable(taxiIn));
}
if(isInteger(Out)){
int taxiOut = Integer.parseInt(Out);
context.write(new Text(airportdep), new 
LongWritable(taxiOut));
}
}
public static boolean isInteger(String s) {
boolean isValidInteger = false;
try
{
Integer.parseInt(s);
// s is a valid integer
isValidInteger = true;
}
catch (NumberFormatException ex)
{
// s is not an integer
}
return isValidInteger;
}
}
public static class Reduce extends Reducer<Text, LongWritable,
Text, Text> {
private DoubleWritable sumCount = new
DoubleWritable();
private DoubleWritable relativeCount = new
DoubleWritable();
public void reduce(Text key, Iterable<LongWritable>
values,
Context context) throws IOException,
InterruptedException {
int count =0;
long TotalValue = 0;
double average = 0.0;
for (LongWritable value : values) {
TotalValue = TotalValue+value.get();
count++;
}
average = TotalValue/count;
sortedOutput.add(new OutputPair(average,
key.toString()));
sortedOutput2.add(new OutputPair(average,
key.toString()));
//System.out.println(sortedOutput.size()+ " soterd output size check
");
if (sortedOutput.size() > 3) {
sortedOutput.pollLast();
}
if (sortedOutput2.size() > 3) {
sortedOutput2.pollFirst();
}
context.write(key,new
Text(Double.toString(average)));
}
}
public static void main(String[] args) throws Exception {
Job job = Job.getInstance(new Configuration());
job.setJarByClass(TaxiAverage.class);
job.setMapperClass(Map.class);
job.setReducerClass(Reduce.class);
FileInputFormat.addInputPath(job, new Path(args[0]));
FileOutputFormat.setOutputPath(job, new Path(args[1]));
job.setMapOutputKeyClass(Text.class);
job.setMapOutputValueClass(LongWritable.class);
job.setOutputKeyClass(Text.class);
job.setOutputValueClass(LongWritable.class);
job.waitForCompletion(true);
File file1 = new File(args[1] + "/top3.txt");
file1.createNewFile();
FileWriter fw1 = new FileWriter(file1);
for (OutputPair now : sortedOutput) {
fw1.write( "Airport name -> " + now.key + "
Highest average time-> " + now.average + "\n");
}
fw1.close();
File file2 = new File(args[1] + "/bottom3.txt");
file2.createNewFile();
FileWriter fw2 = new FileWriter(file2);
for (OutputPair now : sortedOutput2) {
fw2.write( "Airport name -> " + now.key + "
Lowest average time-> " + now.average + "\n");
}
fw2.close();
}
public static class OutputPair implements
Comparable<OutputPair> {
double average;
String key;
OutputPair(double average, String key) {
this.average= average;
this.key = key;
}
@Override
public int compareTo(OutputPair outputPair) {
if(this.average<=outputPair.average){
return 1;
} else {
return -1;
}
}
}
}
